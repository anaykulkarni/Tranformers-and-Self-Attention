{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f02a0ce-1651-4ed4-842a-a7e937aadb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and creating tokenizer ...\n",
      "Vocabulary size is 5755\n",
      "Epoch [1/15], Training Accuracy: 44.02, Test Accuracy: 33.33\n",
      "Epoch [2/15], Training Accuracy: 44.50, Test Accuracy: 45.20\n",
      "Epoch [3/15], Training Accuracy: 47.04, Test Accuracy: 44.80\n",
      "Epoch [4/15], Training Accuracy: 54.54, Test Accuracy: 55.73\n",
      "Epoch [5/15], Training Accuracy: 57.46, Test Accuracy: 66.13\n",
      "Epoch [6/15], Training Accuracy: 64.24, Test Accuracy: 68.67\n",
      "Epoch [7/15], Training Accuracy: 67.88, Test Accuracy: 74.00\n",
      "Epoch [8/15], Training Accuracy: 72.90, Test Accuracy: 69.60\n",
      "Epoch [9/15], Training Accuracy: 77.53, Test Accuracy: 74.40\n",
      "Epoch [10/15], Training Accuracy: 81.60, Test Accuracy: 80.67\n",
      "Epoch [11/15], Training Accuracy: 83.51, Test Accuracy: 73.47\n",
      "Epoch [12/15], Training Accuracy: 85.04, Test Accuracy: 82.80\n",
      "Epoch [13/15], Training Accuracy: 86.81, Test Accuracy: 83.47\n",
      "Epoch [14/15], Training Accuracy: 88.34, Test Accuracy: 84.27\n",
      "Epoch [15/15], Training Accuracy: 89.63, Test Accuracy: 85.07\n",
      "\n",
      "Encoding Sentence: When one nation pursues a nuclear weapon, the risk of nuclear attack rises for all nations.\n",
      "Input tensor shape: torch.Size([1, 32])\n",
      "Number of attention maps = Layers * heads =  8\n",
      "Figure(800x800)\n",
      "\n",
      "Encoding Sentence: The level of world cooperation and condemnation of Iraq is unprecedented.\n",
      "Input tensor shape: torch.Size([1, 32])\n",
      "Number of attention maps = Layers * heads =  8\n",
      "Figure(800x800)\n"
     ]
    }
   ],
   "source": [
    "!python main.py --model part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1ffe28-0064-49e9-8245-aa16ee7d3306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and creating tokenizer ...\n",
      "Vocabulary size is 5755\n",
      "\n",
      "\n",
      "Training and Testing LM for 0: Barack Obama\n",
      "Iteration [100/500], Training Perplexity: 541.26, Test Perplexity: 681.97\n",
      "Iteration [200/500], Training Perplexity: 359.36, Test Perplexity: 515.04\n",
      "Iteration [300/500], Training Perplexity: 253.71, Test Perplexity: 428.42\n",
      "Iteration [400/500], Training Perplexity: 189.89, Test Perplexity: 384.02\n",
      "Iteration [500/500], Training Perplexity: 146.89, Test Perplexity: 372.97\n",
      "\n",
      "\n",
      "Training and Testing LM for 1: George W. Bush\n",
      "Iteration [100/500], Training Perplexity: 589.40, Test Perplexity: 802.20\n",
      "Iteration [200/500], Training Perplexity: 390.43, Test Perplexity: 623.58\n",
      "Iteration [300/500], Training Perplexity: 269.15, Test Perplexity: 506.57\n",
      "Iteration [400/500], Training Perplexity: 194.99, Test Perplexity: 465.07\n",
      "Iteration [500/500], Training Perplexity: 151.61, Test Perplexity: 440.85\n",
      "\n",
      "\n",
      "Training and Testing LM for 2: George H. Bush\n",
      "Iteration [100/500], Training Perplexity: 584.73, Test Perplexity: 724.42\n",
      "Iteration [200/500], Training Perplexity: 375.79, Test Perplexity: 551.61\n",
      "Iteration [300/500], Training Perplexity: 258.34, Test Perplexity: 458.67\n",
      "Iteration [400/500], Training Perplexity: 191.19, Test Perplexity: 423.85\n",
      "Iteration [500/500], Training Perplexity: 148.91, Test Perplexity: 401.78\n",
      "\n",
      "Encoding Sentence: More of you have lost your homes and even more are watching your home values plummet.\n",
      "Input tensor shape: torch.Size([1, 32])\n",
      "Number of attention maps = Layers * heads =  8\n",
      "Figure(800x800)\n",
      "\n",
      "Encoding Sentence: For peace to come, it is time for them, and all of us, to live up to our responsibilities.\n",
      "Input tensor shape: torch.Size([1, 32])\n",
      "Number of attention maps = Layers * heads =  8\n",
      "Figure(800x800)\n"
     ]
    }
   ],
   "source": [
    "!python main.py --model part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42dde784-fcd7-4c0b-b4cf-461ebe8c7295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and creating tokenizer ...\n",
      "Vocabulary size is 5755\n",
      "Comparing performance of a Transformer Encoder Model with FF Classifier on Absolute Positional Encoding (Sinusoidal) vs AliBi (Attention with Linear Biases)\n",
      "\n",
      "Using Absolute Positional Encoding:\n",
      "Epoch [5/100], Training Accuracy: 47.23, Test Accuracy: 44.27\n",
      "Epoch [10/100], Training Accuracy: 54.92, Test Accuracy: 52.40\n",
      "Epoch [15/100], Training Accuracy: 60.76, Test Accuracy: 58.80\n",
      "Epoch [20/100], Training Accuracy: 65.44, Test Accuracy: 62.27\n",
      "Epoch [25/100], Training Accuracy: 69.89, Test Accuracy: 68.80\n",
      "Epoch [30/100], Training Accuracy: 75.76, Test Accuracy: 73.07\n",
      "Epoch [35/100], Training Accuracy: 78.68, Test Accuracy: 76.00\n",
      "Epoch [40/100], Training Accuracy: 82.65, Test Accuracy: 77.47\n",
      "Epoch [45/100], Training Accuracy: 84.70, Test Accuracy: 79.73\n",
      "Epoch [50/100], Training Accuracy: 85.61, Test Accuracy: 82.53\n",
      "Epoch [55/100], Training Accuracy: 86.90, Test Accuracy: 83.07\n",
      "Epoch [60/100], Training Accuracy: 89.05, Test Accuracy: 84.40\n",
      "Epoch [65/100], Training Accuracy: 91.06, Test Accuracy: 84.27\n",
      "Epoch [70/100], Training Accuracy: 90.82, Test Accuracy: 85.07\n",
      "Epoch [75/100], Training Accuracy: 92.40, Test Accuracy: 85.87\n",
      "Epoch [80/100], Training Accuracy: 93.55, Test Accuracy: 85.33\n",
      "Epoch [85/100], Training Accuracy: 93.50, Test Accuracy: 86.27\n",
      "Epoch [90/100], Training Accuracy: 94.46, Test Accuracy: 84.80\n",
      "Epoch [95/100], Training Accuracy: 94.02, Test Accuracy: 86.27\n",
      "Epoch [100/100], Training Accuracy: 95.94, Test Accuracy: 85.73\n",
      "\n",
      "Using AliBi (Attention with Linear Biases):\n",
      "Epoch [5/100], Training Accuracy: 45.41, Test Accuracy: 33.33\n",
      "Epoch [10/100], Training Accuracy: 54.11, Test Accuracy: 54.40\n",
      "Epoch [15/100], Training Accuracy: 62.48, Test Accuracy: 60.00\n",
      "Epoch [20/100], Training Accuracy: 71.65, Test Accuracy: 67.73\n",
      "Epoch [25/100], Training Accuracy: 76.53, Test Accuracy: 72.53\n",
      "Epoch [30/100], Training Accuracy: 80.45, Test Accuracy: 76.00\n",
      "Epoch [35/100], Training Accuracy: 84.56, Test Accuracy: 79.73\n",
      "Epoch [40/100], Training Accuracy: 88.38, Test Accuracy: 82.40\n",
      "Epoch [45/100], Training Accuracy: 90.92, Test Accuracy: 84.80\n",
      "Epoch [50/100], Training Accuracy: 92.78, Test Accuracy: 85.73\n",
      "Epoch [55/100], Training Accuracy: 94.74, Test Accuracy: 84.80\n",
      "Epoch [60/100], Training Accuracy: 95.12, Test Accuracy: 87.07\n",
      "Epoch [65/100], Training Accuracy: 95.70, Test Accuracy: 86.40\n",
      "Epoch [70/100], Training Accuracy: 96.89, Test Accuracy: 86.80\n",
      "Epoch [75/100], Training Accuracy: 96.80, Test Accuracy: 87.73\n",
      "Epoch [80/100], Training Accuracy: 97.47, Test Accuracy: 86.93\n",
      "Epoch [85/100], Training Accuracy: 96.94, Test Accuracy: 87.47\n",
      "Epoch [90/100], Training Accuracy: 98.28, Test Accuracy: 86.93\n",
      "Epoch [95/100], Training Accuracy: 98.42, Test Accuracy: 86.40\n",
      "Epoch [100/100], Training Accuracy: 98.23, Test Accuracy: 86.80\n",
      "\n",
      "Encoding Sentence: Because next week, in Minnesota, the same party that brought you two terms of George Bush and Dick Cheney will ask this country for a third.\n",
      "Input tensor shape: torch.Size([1, 32])\n",
      "Number of attention maps = Layers * heads =  8\n",
      "Figure(800x800)\n",
      "\n",
      "Encoding Sentence: Because next week, in Minnesota, the same party that brought you two terms of George Bush and Dick Cheney will ask this country for a third.\n",
      "Input tensor shape: torch.Size([1, 32])\n",
      "Number of attention maps = Layers * heads =  8\n",
      "Figure(800x800)\n",
      "\n",
      "Plot saved as Figure-train.png\n",
      "\n",
      "Plot saved as Figure-test.png\n"
     ]
    }
   ],
   "source": [
    "!python main.py --model part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c0b33-4137-421d-8776-fe76e9edff2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
