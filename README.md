# Transformer-Encoder-for-speech-classification
- Transformer Encoder with multi-head self-attention coupled with a Feedforward classifier for speech segment classification task.
- Tranformer Decoder (GPT) with masked self-attention to generate speech segments. Additionally, we evaluate the model's perplexity.
